%reload_ext autoreload
%autoreload 2


import os, sys
import re
import json
import glob
import datetime
from collections import Counter

import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns


# Add parent directory to path to import modules from src
rpath = os.path.abspath('..')
if rpath not in sys.path:
    sys.path.insert(0, rpath)

from src.loader import SlackDataLoader
import src.utils as utils








# combine all json file in all-weeks8-9
def slack_parser(path_channel):
    """ parse slack data to extract useful informations from the json file
        step of execution
        1. Import the required modules
        2. read all json file from the provided path
        3. combine all json files in the provided path
        4. extract all required informations from the slack data
        5. convert to dataframe and merge all
        6. reset the index and return dataframe
    """

    # specify path to get json files
    combined = []
    for json_file in glob.glob(f"{path_channel}*.json"):
        with open(json_file, 'r', encoding="utf8") as slack_data:
            data=json.load(slack_data)
            combined.append(data)

    # loop through all json files and extract required informations
    dflist = []
    for slack_data in combined:

        msg_type, msg_content, sender_id, time_msg, msg_dist, time_thread_st, reply_users, \
        reply_count, reply_users_count, tm_thread_end = [],[],[],[],[],[],[],[],[],[]

        for row in slack_data:
            if 'bot_id' in row.keys():
                continue
            else:
                msg_type.append(row['type'])
                msg_content.append(row['text'])
                if 'user_profile' in row.keys(): sender_id.append(row['user_profile']['real_name'])
                else: sender_id.append('Not provided')
                time_msg.append(row['ts'])
                if 'blocks' in row.keys() and row['blocks'] is not None and len(row['blocks'][0]['elements'][0]['elements']) != 0:
                    msg_dist.append(row['blocks'][0]['elements'][0]['elements'][0]['type'])
                else: msg_dist.append('reshared')
                if 'thread_ts' in row.keys():
                    time_thread_st.append(row['thread_ts'])
                else:
                    time_thread_st.append(0)
                if 'reply_users' in row.keys(): reply_users.append(",".join(row['reply_users'])) 
                else:    reply_users.append(0)
                if 'reply_count' in row.keys():
                    reply_count.append(row['reply_count'])
                    reply_users_count.append(row['reply_users_count'])
                    tm_thread_end.append(row['latest_reply'])
                else:
                    reply_count.append(0)
                    reply_users_count.append(0)
                    tm_thread_end.append(0)
        data = zip(msg_type, msg_content, sender_id, time_msg, msg_dist, time_thread_st,
         reply_count, reply_users_count, reply_users, tm_thread_end)
        columns = ['msg_type', 'msg_content', 'sender_name', 'msg_sent_time', 'msg_dist_type',
         'time_thread_start', 'reply_count', 'reply_users_count', 'reply_users', 'tm_thread_end']

        df = pd.DataFrame(data=data, columns=columns)
        df = df[df['sender_name'] != 'Not provided']
        dflist.append(df)

    dfall = pd.concat(dflist, ignore_index=True)
    dfall['channel'] = path_channel.split('/')[-1].split('.')[0]        
    dfall = dfall.reset_index(drop=True)
    
    return dfall

    # return dfall


def parse_slack_reaction(path, channel):
    """get reactions"""
    dfall_reaction = pd.DataFrame()
    combined = []
    for json_file in glob.glob(f"{path}*.json"):
        with open(json_file, 'r') as slack_data:
            data = json.load(slack_data)
            combined.append(data)

    reaction_name, reaction_count, reaction_users, msg, user_id = [], [], [], [], []

    for slack_data in combined:
        # slack_data = json.load(open(k.name, 'r', encoding="utf-8"))

        for i_count, i in enumerate(slack_data):
            if 'reactions' in i.keys():
                for j in range(len(i['reactions'])):
                    msg.append(i['text'])
                    user_id.append(i['user'])
                    reaction_name.append(i['reactions'][j]['name'])
                    reaction_count.append(i['reactions'][j]['count'])
                    reaction_users.append(",".join(i['reactions'][j]['users']))

    data_reaction = zip(reaction_name, reaction_count, reaction_users, msg, user_id)
    columns_reaction = ['reaction_name', 'reaction_count', 'reaction_users_count', 'message', 'user_id']
    df_reaction = pd.DataFrame(data=data_reaction, columns=columns_reaction)
    df_reaction['channel'] = channel
    return df_reaction

def get_community_participation(path):
    """ specify path to get json files"""
    combined = []
    comm_dict = {}
    for json_file in glob.glob(f"{path}*.json"):
        with open(json_file, 'r') as slack_data:
            combined.append(slack_data)
    # print(f"Total json files is {len(combined)}")
    for i in combined:
        a = json.load(open(i.name, 'r', encoding='utf-8'))

        for msg in a:
            if 'replies' in msg.keys():
                for i in msg['replies']:
                    comm_dict[i['user']] = comm_dict.get(i['user'], 0)+1
    return comm_dict


def convert_2_timestamp(column, data):
    """convert from unix time to readable timestamp
        args: column: columns that needs to be converted to timestamp
                data: data that has the specified column
    """
    if column in data.columns.values:
        timestamp_ = []
        for time_unix in data[column]:
            if time_unix == 0:
                timestamp_.append(0)
            else:
                a = datetime.datetime.fromtimestamp(float(time_unix))
                timestamp_.append(a.strftime('%Y-%m-%d %H:%M:%S'))
        return timestamp_
    else:
        print(f"{column} not in data")

def get_tagged_users(df):
    """get all @ in the messages"""

    return df['msg_content'].map(lambda x: re.findall(r'@U\w+', x))


def map_userid_2_realname(user_profile: dict, comm_dict: dict, plot=False):
    """
    map slack_id to realnames
    user_profile: a dictionary that contains users info such as real_names
    comm_dict: a dictionary that contains slack_id and total_message sent by that slack_id
    """
    user_dict = {} # to store the id
    real_name = [] # to store the real name
    ac_comm_dict = {} # to store the mapping
    count = 0
    # collect all the real names
    for i in range(len(user_profile['profile'])):
        real_name.append(dict(user_profile['profile'])[i]['real_name'])

    # loop the slack ids
    for i in user_profile['id']:
        user_dict[i] = real_name[count]
        count += 1

    # to store mapping
    for i in comm_dict:
        if i in user_dict:
            ac_comm_dict[user_dict[i]] = comm_dict[i]

    ac_comm_dict = pd.DataFrame(data= zip(ac_comm_dict.keys(), ac_comm_dict.values()),
    columns=['LearnerName', '# of Msg sent in Threads']).sort_values(by='# of Msg sent in Threads', ascending=False)
    
    if plot:
        ac_comm_dict.plot.bar(figsize=(15, 7.5), x='LearnerName', y='# of Msg sent in Threads')
        plt.title('Student based on Message sent in thread', size=20)
        
    return ac_comm_dict


def get_top_20_user(data, channel='Random'):
    """get user with the highest number of message sent to any channel"""

    data['sender_name'].value_counts()[:20].plot.bar(figsize=(15, 7.5))
    plt.title(f'Top 20 Message Senders in #{channel} channels', size=15, fontweight='bold')
    plt.xlabel("Sender Name", size=18); plt.ylabel("Frequency", size=14);
    plt.xticks(size=12); plt.yticks(size=12);
    plt.show()

    data['sender_name'].value_counts()[-10:].plot.bar(figsize=(15, 7.5))
    plt.title(f'Bottom 10 Message Senders in #{channel} channels', size=15, fontweight='bold')
    plt.xlabel("Sender Name", size=18); plt.ylabel("Frequency", size=14);
    plt.xticks(size=12); plt.yticks(size=12);
    plt.show()
def get_bottom_10_user(data,channel):
    data['sender_name'].value_counts()[-10:].plot.bar(figsize=(15, 7.5))
    plt.title(f'Bottom 10 Message Senders in #{channel} channels', size=15, fontweight='bold')
    plt.xlabel("Sender Name", size=18); plt.ylabel("Frequency", size=14);
    plt.xticks(size=12); plt.yticks(size=12);
    plt.show()
    
def get_bottom_10_user_reaction(data,channel):
    data['user_id'].value_counts()[-10:].plot.bar(figsize=(15, 7.5))
    plt.title(f'Bottom 10 Message Senders in #{channel} channels', size=15, fontweight='bold')
    plt.xlabel("Sender Name", size=18); plt.ylabel("Frequency", size=14);
    plt.xticks(size=12); plt.yticks(size=12);
    plt.show()
    

def draw_avg_reply_count(data, channel='Random'):
    """who commands many reply?"""

    data.groupby('sender_name')['reply_count'].mean().sort_values(ascending=False)[:20]\
        .plot(kind='bar', figsize=(15,7.5));
    plt.title(f'Average Number of reply count per Sender in #{channel}', size=20, fontweight='bold')
    plt.xlabel("Sender Name", size=18); plt.ylabel("Frequency", size=18);
    plt.xticks(size=14); plt.yticks(size=14);
    plt.show()

def draw_avg_reply_users_count(data, channel='Random'):
    """who commands many user reply?"""

    data.groupby('sender_name')['reply_users_count'].mean().sort_values(ascending=False)[:20].plot(kind='bar',
     figsize=(15,7.5));
    plt.title(f'Average Number of reply user count per Sender in #{channel}', size=20, fontweight='bold')
    plt.xlabel("Sender Name", size=18); plt.ylabel("Frequency", size=18);
    plt.xticks(size=14); plt.yticks(size=14);
    plt.show()

def draw_wordcloud(msg_content, week):
    # word cloud visualization
    allWords = ' '.join([twts for twts in msg_content])
    wordCloud = WordCloud(background_color='#975429', width=500, height=300, random_state=21, max_words=500, mode='RGBA',
                            max_font_size=140, stopwords=stopwords.words('english')).generate(allWords)
    plt.figure(figsize=(15, 7.5))
    plt.imshow(wordCloud, interpolation="bilinear")
    plt.axis('off')
    plt.tight_layout()
    plt.title(f'WordCloud for {week}', size=30)
    plt.show()

def draw_user_reaction(data, channel='General'):
    data.groupby('sender_name')[['reply_count', 'reply_users_count']].sum()\
        .sort_values(by='reply_count',ascending=False)[:10].plot(kind='bar', figsize=(15, 7.5))
    plt.title(f'User with the most reaction in #{channel}', size=25);
    plt.xlabel("Sender Name", size=18); plt.ylabel("Frequency", size=18);
    plt.xticks(size=14); plt.yticks(size=14);
    plt.show()

def plot_common_words(json_file_path, channel_name):
    # Read the JSON file
    with open(json_file_path, 'r', encoding="utf8") as json_file:
        data = json.load(json_file)

    # Convert the data to a DataFrame (adjust as per your JSON structure)
    df = pd.DataFrame(data)

    # Filter messages for the specified channel
    channel_data = df[df['channel'] == channel_name]

    # Combine the text of messages in the channel
    all_text = ' '.join([str(msg.get('text', '')) for msg in channel_data['topic']])

    # Split the text into words
    words = all_text.split()

    # Create a pandas Series for easy word counting
    word_counts = pd.Series(words).value_counts()

    # Plot the top N words
    top_n = 20  # Change this value to adjust the number of words to display
    plt.figure(figsize=(12, 6))
    word_counts.head(top_n).plot(kind='bar', color='skyblue')
    plt.title(f'Top {top_n} Words in #{channel_name}')
    plt.xlabel('Words')
    plt.ylabel('Frequency')
    plt.xticks(rotation=45, ha='right')
    plt.show()

#plot of top users with highest replies per message.
def plot_visualize_top_10_users_with_highest_reply_count(data: pd.DataFrame):
    grouped_df = data.groupby('sender_name')['reply_count'].sum()
    grouped_df = grouped_df.sort_values(ascending=False)
    grouped_df.plot(kind='bar', figsize=(15, 7.5))
    plt.yscale('log')
    plt.title('Reply Counts of users')
    plt.xlabel('User')
    plt.ylabel('Number of Replies')
    plt.show()





def create_dataframe() -> pd.DataFrame:
    DIR = '../anonymized/'
    sl = SlackDataLoader(DIR)
    data_frames = [
        slack_parser(DIR + channel['name'] + '/')
        for channel in sl.get_channels()
    ]
    all_data = pd.concat(data_frames, ignore_index=True)
    return all_data


dframe = create_dataframe()
dframe


# plot users from top to bottom based on replay count
def plot_highest_replies_per_user(data: pd.DataFrame):
    grouped_df = data.groupby('sender_name')['reply_count'].sum()
    grouped_df = grouped_df.sort_values(ascending=False)
    grouped_df.plot(kind='bar', figsize=(15, 7.5))
    plt.yscale('log')
    plt.title('Reply Counts of users')
    plt.xlabel('User')
    plt.ylabel('Number of replies')
    plt.show()



plot_highest_replies_per_user(dframe)


# Top 10 users with highest reply count
plot_visualize_top_10_users_with_highest_reply_count(dframe)


def get_top_users_by_replies_count(data: pd.DataFrame, top_n=10):
    top_users = data.nlargest(top_n, 'reply_count')[['sender_name', 'reply_count']]
    return top_users


#display users with highest replies
get_top_users_by_replies_count(dframe)


def get_bottom_users_by_replies_count(data: pd.DataFrame, bottom_n=10):
    bottom_users = data.nsmallest(bottom_n, 'reply_count')[['sender_name', 'reply_count']]
    return bottom_users


get_bottom_users_by_replies_count(dframe)


#plot for top 10 users with reply count
def plot_top_users_with_highest_replies(data: pd.DataFrame, top_n=10):
    top_users = get_top_users_by_replies_count(data, top_n)

    plt.figure(figsize=(16, 8))
    plt.bar(top_users['sender_name'], top_users['reply_count'], color='pink')
    plt.yscale('log')
    plt.title(f'Top {top_n} Users with the Highest Replies')
    plt.xlabel('User')
    plt.ylabel('Number of Replies')
    plt.show()


plot_top_users_with_highest_replies(dframe)


def plot_top_users_with_lowest_replies(data: pd.DataFrame, top_n=10):
    bottom_users = get_bottom_users_by_replies_count(data, top_n)

    plt.figure(figsize=(12, 6))
    plt.scatter(bottom_users['sender_name'], bottom_users['reply_count'], color='pink', s=100)
    plt.title(f'Top {top_n} Users with the Lowest Replies (Logarithmic Scale)')
    plt.xlabel('User')
    plt.ylabel('Number of Replies (Log Scale)')
    plt.xticks(rotation=45, ha='right')
    plt.show()

def get_bottom_users_by_replies_count(data: pd.DataFrame, top_n=10):
    return data.nsmallest(top_n, 'reply_count')[['sender_name', 'reply_count']]


plot_top_users_with_lowest_replies(dframe)


def get_top_users_by_message_count(data: pd.DataFrame, top_n=10):
    user_counts = data.groupby('sender_name').size()
    top_users = user_counts.nlargest(top_n).reset_index(name='message_count')
    return top_users


get_top_users_by_message_count(dframe)


def get_bottom_users_by_message_count(data: pd.DataFrame, top_n=10):
    user_counts = data.groupby('sender_name').size()
    bottom_users = user_counts.nsmallest(top_n).reset_index(name='message_count')
    return bottom_users


get_bottom_users_by_message_count(dframe)


def extract_mentions(data: pd.DataFrame):
    user_ids = get_tagged_users(data)
    clean_ids = [id[0][1:] for id in user_ids if id]
    
    return pd.DataFrame({'user_id': clean_ids})


#mentions    
def mentions(data: pd.DataFrame):
    user_ids = get_tagged_users(data)
    ids_list = []
    for id in user_ids:
        if id:
            ids_list.append(id[0][1:])

    print(pd.DataFrame({'user_id': ids_list}))
    return pd.DataFrame({'user_id': ids_list})

def load_user_names_df(slack_loader):
    slack_loader.get_users()
    # print(slack_loader.get_user_map()[0])
    users_map = slack_loader.get_user_map()[0]
    pf=pd.DataFrame({'user_id': list(users_map.keys()), 'user_name': list(users_map.values())})
    return pf
def merge_user_names_with_mentions(user_names_df, all_userids_mentioned):
    return user_names_df.merge(all_userids_mentioned, on='user_id', how='outer')


get_tagged_users(dframe).shape


# def get_top_users_by_mentions(data: pd.DataFrame, top_n=10):
#     mention_counts = data.groupby('user_name').size()
#     top_users = mention_counts.nlargest(top_n).reset_index(name='mention_count')
#     return top_users
DIR = '../anonymized/'
sl = SlackDataLoader(DIR)
pfill = load_user_names_df(sl)
pfill



DIR = '../anonymized/'
sl = SlackDataLoader(DIR)
all_userids_mentioned = extract_mentions(dframe)

user_names_df = load_user_names_df(sl)
mentioned_users_df = merge_user_names_with_mentions(user_names_df, all_userids_mentioned)
user_names_df.shape


def users_with_highest_mentions(data: pd.DataFrame):
    counts = data.groupby('user_name').size()
    top_users = counts.sort_values(ascending=False).head(10)
    result = pd.DataFrame({
        'user_name' : top_users.index,
        'mention_count' : top_users.values
    })
    return result


users_with_highest_mentions(mentioned_users_df)



